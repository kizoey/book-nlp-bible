{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Ch 20. 순환 신경망(RNN).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP5Te38Lkqco1tTZph9aUgz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"wrCLcpNYxVGs"},"source":["# 실습 [20-1]<br>\n","**실습명: 기본 순환 신경망(Vanilla RNN)**<br>\n"]},{"cell_type":"code","metadata":{"id":"Y23XbmmuzxXn"},"source":["!pip install tensorflow\n","!pip install keras"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ozFTVU0xD3D","executionInfo":{"status":"ok","timestamp":1624350105519,"user_tz":-540,"elapsed":677,"user":{"displayName":"DA YEON KI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWfZD29yea7akQsMZ0L-JyyDBDzCak-4Q55tt-jw=s64","userId":"15097711384147757777"}},"outputId":"06e58dbf-0c8d-4f34-d2c8-083c546152cb"},"source":["#어휘 사이즈=1000\n","#은닉 벡터 사이즈=64\n","#RNN 내부 유닛=128\n","#출력 클래스 개수=10\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","\n","model = tf.keras.Sequential()\n","model.add(layers.Embedding(input_dim=1000, output_dim=64)) #단어 임베딩 계층\n","model.add(layers.SimpleRNN(128))\n","model.add(layers.Dense(10, activation='softmax')) #output shape 변환 용도\n","model.summary()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 64)          64000     \n","_________________________________________________________________\n","simple_rnn (SimpleRNN)       (None, 128)               24704     \n","_________________________________________________________________\n","dense (Dense)                (None, 10)                1290      \n","=================================================================\n","Total params: 89,994\n","Trainable params: 89,994\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JvJiIjzJxdei"},"source":["# 실습 [20-2]<br>\n","**실습명: 장단기 메모리(LSTM)**<br>\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SwMaNRmOxh4K","executionInfo":{"status":"ok","timestamp":1624350264254,"user_tz":-540,"elapsed":616,"user":{"displayName":"DA YEON KI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWfZD29yea7akQsMZ0L-JyyDBDzCak-4Q55tt-jw=s64","userId":"15097711384147757777"}},"outputId":"766ac9f4-cef6-4f5d-ad25-93e1dcdb6a76"},"source":["#어휘 사이즈=1000\n","#은닉 벡터 사이즈=64\n","#LSTM 내부 유닛=128\n","#출력 클래스 개수=10\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","\n","model = tf.keras.Sequential()\n","model.add(layers.Embedding(input_dim=1000, output_dim=64)) #단어 임베딩 계층\n","model.add(layers.LSTM(128))\n","model.add(layers.Dense(10, activation='softmax')) #output shape 변환 용도\n","model.summary()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, None, 64)          64000     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 128)               98816     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 164,106\n","Trainable params: 164,106\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kL0-Y70rxiNV"},"source":["# 실습 [20-3]<br>\n","**실습명: 게이트 순환 유닛(GRU)**<br>\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iu6mi-iExnS2","executionInfo":{"status":"ok","timestamp":1624350351063,"user_tz":-540,"elapsed":670,"user":{"displayName":"DA YEON KI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiWfZD29yea7akQsMZ0L-JyyDBDzCak-4Q55tt-jw=s64","userId":"15097711384147757777"}},"outputId":"9500b305-9750-46a3-bd67-1f250e9058de"},"source":["#어휘 사이즈=1000\n","#은닉 벡터 사이즈=64\n","#GRU 내부 유닛=256\n","#RNN 내부 유닛=128\n","#출력 클래스 개수=10\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","\n","model = tf.keras.Sequential()\n","model.add(layers.Embedding(input_dim=1000, output_dim=64)) #단어 임베딩 계층\n","model.add(layers.GRU(256, return_sequences=True))\n","#GRU는 LSTM과 달리 (배치 크기, 타임 스텝, 은닉 사이즈)의 3D tensor 출력\n","model.add(layers.SimpleRNN(128))\n","model.add(layers.Dense(10, activation='softmax')) #output shape 변환 용도\n","model.summary()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_3 (Embedding)      (None, None, 64)          64000     \n","_________________________________________________________________\n","gru (GRU)                    (None, None, 256)         247296    \n","_________________________________________________________________\n","simple_rnn_1 (SimpleRNN)     (None, 128)               49280     \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 361,866\n","Trainable params: 361,866\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]}]}